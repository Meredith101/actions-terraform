name: CI/CD # The name of your workflow, visible in the GitHub Actions tab

on:
  push:
    branches:
      - main # This workflow will trigger automatically on pushes to the 'main' branch

jobs:
  # --- CI Pipeline Job: Builds and tests your application ---
  buildAndTest:
    name: CI Pipeline
    runs-on: ubuntu-latest # Specifies the type of runner to use

    env:
      # Environment variables for your test setup
      NODE_ENV: test
      DB_HOST: localhost
      POSTGRES_USER: test
      POSTGRES_PASSWORD: postgres
      POSTGRES_DB: test_db

    steps:
      - name: Checkout code
        uses: actions/checkout@v4 # Essential step to get your repository code onto the runner

      - name: Setup Node.js
        uses: actions/setup-node@v4 # Sets up Node.js environment

      - name: Set up PostgreSQL
        uses: Harmon758/postgresql-action@v1 # Action to start a PostgreSQL service for testing
        with:
          postgresql version: '13'
          postgresql db: ${{ env.POSTGRES_DB }}
          postgresql user: ${{ env.POSTGRES_USER }}
          postgresql password: ${{ env.POSTGRES_PASSWORD }}

      - name: Install Angular dependencies
        run: npm ci # Installs dependencies for your Angular frontend

      - name: Run Angular Tests
        run: npm run test:coverage # Executes Angular tests and collects coverage

      - name: Install Express dependencies
        run: npm --prefix ./server ci # Installs dependencies for your Express backend

      - name: Run Linting
        run: npm --prefix ./server run lint # Runs linting checks on your Express code

      - name: Run Migration
        run: npm --prefix ./server run migrate # Runs database migrations

      - name: Run Express Tests
        run: npm --prefix ./server run coverage

  # --- Push Image Job: Builds and pushes your Docker image to ECR ---
  push_image:
    runs-on: ubuntu-latest
    needs: buildAndTest # This job will only run if 'buildAndTest' job completes successfully
    outputs:
      # This output will pass the generated image tag to the 'deploy' job
      image_tag_output: ${{ steps.generate_tag.outputs.dynamic_image_tag }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials # Now using direct access keys from GitHub secrets
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }} # Ensure this secret is set in GitHub
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }} # Ensure this secret is set in GitHub
          aws-region: eu-west-2

      - name: Get current date for image tag
        id: generate_tag # ID for this step to reference its output
        run: |
          # Generates a timestamp (e.g., 20250610164849) to use as a unique Docker image tag
          TIMESTAMP=$(date +'%Y%m%d%H%M%S')
          echo "Generated TIMESTAMP for image tag: $TIMESTAMP"

          # IMPORTANT: Exports 'IMAGE_TAG' as an environment variable for subsequent steps in THIS job
          echo "IMAGE_TAG=$TIMESTAMP" >> $GITHUB_ENV

          # IMPORTANT: Exports 'dynamic_image_tag' as a step output for other jobs to consume
          echo "dynamic_image_tag=$TIMESTAMP" >> $GITHUB_OUTPUT

      - name: Login to Amazon ECR
        uses: aws-actions/amazon-ecr-login@v2 # Logs into your Amazon ECR registry

      - name: Build, tag, and push image to Amazon ECR
        env:
          ECR_REPOSITORY_NAME: "sams" # Your specific ECR repository name
          # 'IMAGE_TAG' is now available from the GITHUB_ENV set in the previous step
          IMAGE_TAG: ${{ env.IMAGE_TAG }}
        run: |
          # Constructs the full Docker image URI using the ECR registry (from login-ecr) and the tag
          FULL_IMAGE_URI="${{ steps.login-ecr.outputs.registry }}/${{ env.ECR_REPOSITORY_NAME }}:${{ env.IMAGE_TAG }}"
          LATEST_IMAGE_URI="${{ steps.login-ecr.outputs.registry }}/${{ env.ECR_REPOSITORY_NAME }}:latest"

          # Builds your Docker image (assuming Dockerfile is in the repository root)
          docker build -t "$FULL_IMAGE_URI" .
          docker push "$FULL_IMAGE_URI"       # Pushes the uniquely tagged image to ECR

          docker tag "$FULL_IMAGE_URI" "$LATEST_IMAGE_URI" # Tags the same image as 'latest'
          docker push "$LATEST_IMAGE_URI"                   # Pushes the 'latest' tag to ECR

  # --- Deploy Job: Provisions/updates infrastructure and deploys to Elastic Beanstalk ---
  deploy:
    runs-on: ubuntu-latest
    needs: push_image # This job will only run if 'push_image' job completes successfully
    env:
      # AWS Region for all AWS CLI and Terraform commands in this job
      AWS_REGION: eu-west-2

      # ECR Details (must match the repository name used in 'push_image' job)
      ECR_REPOSITORY_NAME: "sams"
      # Retrieve the exact image tag pushed from the 'push_image' job's output
      DEPLOY_IMAGE_TAG: ${{ needs.push_image.outputs.image_tag_output }}

      # Elastic Beanstalk Application & Environment Names
      ELASTIC_BEANSTALK_APP_NAME: "sams-app"
      ELASTIC_BEANSTALK_ENV_NAME: "sams-env"

      # S3 Bucket for Elastic Beanstalk deployment bundles.
      # IMPORTANT: This bucket should be defined and managed by your Terraform configuration
      S3_DEPLOY_BUCKET_NAME: "meredith-bucket" # Ensure this matches your Terraform configuration

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials # Now using direct access keys from GitHub secrets
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }} # Ensure this secret is set in GitHub
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }} # Ensure this secret is set in GitHub
          aws-region: ${{ env.AWS_REGION }}

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          # Specify the Terraform version to ensure consistent behavior
          terraform_version: 1.6.0

      - name: Create Dockerrun.aws.json and deployment bundle
        id: create_bundle # Unique ID for this step
        run: |
          # Constructs the full ECR image URI using the generated tag from the previous job
          # NOTE: We're still using secrets.AWS_ACCOUNT_ID here as part of the ECR registry URI.
          # If you don't have this as a secret, you'll need to hardcode your AWS Account ID here.
          ECR_REGISTRY_URI="${{ secrets.AWS_ACCOUNT_ID }}.dkr.ecr.${{ env.AWS_REGION }}.amazonaws.com"
          FULL_ECR_IMAGE_URI="${ECR_REGISTRY_URI}/${{ env.ECR_REPOSITORY_NAME }}:${{ env.DEPLOY_IMAGE_TAG }}"

          # Dynamically creates the Dockerrun.aws.json file in the repository root
          # This file tells Elastic Beanstalk how to run your Docker container
          cat <<EOF > Dockerrun.aws.json
          {
            "AWSEBDockerrunVersion": "1",
            "Image": {
              "Name": "${FULL_ECR_IMAGE_URI}",
              "Update": "true"
            },
            "Ports": [
              {
                "ContainerPort": 80 # <<< IMPORTANT: Adjust this to your Node.js application's actual listening port inside the Docker container (e.g., 80, 3000, 8080). Elastic Beanstalk will map this to port 80/443 on the load balancer.
              }
            ],
            "Volumes": [],
            "Logging": "/var/log/nginx" # Standard Nginx logs for the proxy, adjust if your Docker image has different logging needs
          }
          EOF

          # Creates a uniquely named .zip bundle containing the Dockerrun.aws.json file
          # This bundle is what Elastic Beanstalk uses for deployments
          BUNDLE_NAME="${{ env.ELASTIC_BEANSTALK_APP_NAME }}-${{ env.DEPLOY_IMAGE_TAG }}.zip"
          zip -r "$BUNDLE_NAME" Dockerrun.aws.json

          # Outputs the bundle name for use in subsequent steps (especially by Terraform)
          echo "bundle_name=$BUNDLE_NAME" >> $GITHUB_OUTPUT

      - name: Upload deployment bundle to S3
        run: |
          # Copies the created .zip bundle to your designated S3 deployment bucket
          aws s3 cp "${{ steps.create_bundle.outputs.bundle_name }}" "s3://${{ env.S3_DEPLOY_BUCKET_NAME }}/"

      - name: Terraform Init
        id: init
        run: terraform init \
          -backend-config="bucket=${{ env.S3_DEPLOY_BUCKET_NAME }}" \
          -backend-config="key=terraform/terraform.tfstate" \
          -backend-config="region=${{ env.AWS_REGION }}"
        working-directory: ./terraform # Ensures Terraform commands run from the 'terraform' directory

      - name: Terraform Plan
        id: plan
        run: terraform plan -input=false -out=tfplan \
          -var="project_name=${{ env.ELASTIC_BEANSTALK_APP_NAME }}" \
          -var="environment=${{ env.ELASTIC_BEANSTALK_ENV_NAME }}" \
          -var="ecr_repository_name=${{ env.ECR_REPOSITORY_NAME }}" \
          -var="app_version_label=${{ env.DEPLOY_IMAGE_TAG }}" \
          -var="db_password=${{ secrets.TF_VAR_db_password }}" \
          -var="vpc_id=${{ secrets.TF_VAR_vpc_id }}" \
          -var="eb_subnet_ids=[${{ secrets.TF_VAR_eb_subnet_ids }}]" \
          -var="s3_bundle_key=${{ steps.create_bundle.outputs.bundle_name }}" # Pass the S3 object key to Terraform
        working-directory: ./terraform

      - name: Terraform Apply
        id: apply
        run: terraform apply -input=false tfplan
        working-directory: ./terraform

      - name: Get Elastic Beanstalk Environment URL
        id: get_url
        run: |
          # Retrieves the deployed Elastic Beanstalk environment URL from Terraform outputs
          EB_URL=$(terraform output -raw elastic_beanstalk_environment_url)
          echo "eb_url=${EB_URL}" >> $GITHUB_OUTPUT
        working-directory: ./terraform

      - name: Echo EB URL
        run: |
          echo "Elastic Beanstalk Application deployed successfully!"
          echo "URL: ${{ steps.get_url.outputs.eb_url }}"